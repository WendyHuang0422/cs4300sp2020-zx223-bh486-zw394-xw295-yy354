{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WendyHuang0422/cs4300sp2020-zx223-bh486-zw394-xw295-yy354/blob/master/AdHoc_Data_Crawl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6cPRad-ptEa"
   },
   "outputs": [],
   "source": [
    "def create_ApI(consumer_key,s_consmer_key,access_key,s_acess_key):\n",
    "  #given the authroization return a tweepy api object for retrieving data\n",
    "  auth = tweepy.OAuthHandler(consumer_key, s_consmer_key)\n",
    "  auth.set_access_token(access_key, s_acess_key)\n",
    "  api = tweepy.API(auth)\n",
    "  return api\n",
    "\n",
    "def tweet_score(status,timeline):\n",
    "  \"\"\"\n",
    "  the current version assign score simply by the time-stamp\n",
    "  the greater the score assigned is, the more relevant it is\n",
    "  status: the particular status that we want to assign a score to\n",
    "  timeline: the entire list of retrieved status\n",
    "  \"\"\"\n",
    "  time = [int(x) for x in list(filter(None,re.split('[\\s:-]',str(status.created_at))))]\n",
    "  score = (time[0]-2000)*120 + time[1]*10 + time[2] + time[3]/12\n",
    "  return score\n",
    "\n",
    "def retrieve_tweets(N,celeb_name,inc_retweets,api):\n",
    "  \"\"\"\n",
    "  help to retrieve the needed number of tweets beyond the number 20\n",
    "  this function does not assigne scores to each tweets\n",
    "  N: the number of wanted tweets\n",
    "  celeb_name: the screen name of the celebrity\n",
    "  inc_retweets: a boolean varibale indicating whether retweets\n",
    "                are going to be included\n",
    "  \"\"\"\n",
    "  if inc_retweets:\n",
    "    return list(api.user_timeline(screen_name = celeb_name,count = N))\n",
    "\n",
    "  pool = list(api.user_timeline(screen_name = celeb_name,count = 2*N))\n",
    "  result = []\n",
    "  count = 0\n",
    "  while count<20: \n",
    "    for status in pool[:-1]:\n",
    "      if not hasattr(status,'retweeted_status'):\n",
    "        result.append(status)\n",
    "      if len(result) == N:\n",
    "        return result\n",
    "    last = pool[-1].id\n",
    "    pool = list(api.user_timeline(screen_name = celeb_name,count = 2*N,\\\n",
    "                                  since_id = 1,max_id=last))\n",
    "    count += 1\n",
    "  return (None,'the user made no recent tweets, try include retweets')\n",
    "\n",
    "\n",
    "def tweets_crawl(N,pool_size,celeb_name,api,inc_retweets):\n",
    "  \"\"\" \n",
    "    retrieve the top N tweets tweeted by the celeb_account\n",
    "    N: the number of wnated accounts\n",
    "\n",
    "    celeb_name: a string, the screen_name of the celebrity\n",
    "    api: the tweepy api object\n",
    "    pool_size: the size of the pool of potential tweets from which we retrieve\n",
    "      N most significant\n",
    "    inc_retweets: whether we include retweets, set to False to retrieve only\n",
    "    original tweets\n",
    "  \"\"\"\n",
    "  timeline = retrieve_tweets(pool_size,celeb_name,inc_retweets,api)\n",
    "  if timeline[0] is None:\n",
    "    print(timeline[1])\n",
    "    return\n",
    "  sorted_timeline = []\n",
    "  for status in timeline:\n",
    "    score = tweet_score(status,timeline)\n",
    "    sorted_timeline.append((status,score))\n",
    "  sorted_timeline = sorted(sorted_timeline,key=lambda x:x[1],reverse = True)\n",
    "  return sorted_timeline[:N]\n",
    "\n",
    "\n",
    "def twittter_aggregated(N,pool_size,celeb_name,inc_retweets):\n",
    "  \"\"\"\n",
    "  the aggregated retrieval function  to retrieve N most recent tweets from pool_size\n",
    "  potential tweets, for example, 200 tweets from 400 tweets in the format\n",
    "  specified in the google doc (a list of dictionaries with each dictionary\n",
    "  representing a tweet). \n",
    "  Call this function in the other stages of the system\n",
    "\n",
    "  READ: this function depends on \n",
    "  tweepy\n",
    "  math\n",
    "  urllib\n",
    "  json\n",
    "  import these modules before calling\n",
    "\n",
    "  N: the number of wnated accounts\n",
    "\n",
    "  celeb_name: a string, the screen_name of the celebrity\n",
    "  api: the tweepy api object\n",
    "  pool_size: the size of the pool of potential tweets from which we retrieve\n",
    "    N most significant\n",
    "  inc_retweets: whether we include retweets, set to False to retrieve only\n",
    "    original tweets\n",
    "  \"\"\"\n",
    "  \n",
    "  c_key = '4xQ7FcDfGAlAM5JkG505ndS3k'\n",
    "  s_c_key = 'GJkKVtF34AoqaXSdCXq6agxCKrj1T2FL9i2w28Yj9t2wCo6jmM'\n",
    "  a_key =  '1247186585994637312-6ZuAFM9bhsv1Mil7utLrL0stxbT8ft'\n",
    "  s_a_key = 'PkPrIdOOPSoQwCM0TuKF4dqLiKOOdTemEpjh2Ewf44FUd'\n",
    "  api =  create_ApI(c_key,s_c_key,a_key,s_a_key)\n",
    "  user = api.get_user(screen_name='realDonaldTrump')\n",
    "  data = []\n",
    "\n",
    "\n",
    "  wanted = ['text','created_at','id','retweet_count','favorite_count']\n",
    "  count = 0\n",
    "  recent = tweets_crawl(N,pool_size,celeb_name,api,inc_retweets)\n",
    "  print(recent[-1])\n",
    "  for idx in recent:\n",
    "    idx = idx[0]._json\n",
    "    temp = {x:idx[x] for x in wanted}\n",
    "    data.append(temp)\n",
    "  return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object\n",
    "#all these keys should go into a json (or the provided secrect environment file\n",
    "#later for secrecy\n",
    "\n",
    "guardian_key = '7dd62f93-de59-4cb6-a166-e7c44543477d'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#with open('/content/drive/My Drive/Twitter_Account.txt',\"w\") as outfile:\n",
    "  #json.dump(data,outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vRVUOdgF1SwW"
   },
   "source": [
    "Bing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOmHVC1ByClh"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def raw_news_retrieval(query,api_key,date1,date2,N,page,sort):\n",
    "  \"\"\"\n",
    "  return a json file specified in \n",
    "  query: a tuple or a keyword, the tuple should represent\n",
    "        \n",
    "  api_key: the auth key to retrieve the news\n",
    "  time_span: a string in the format of 'yyyy-mm-dd:yyyy-mm-dd' indicating the\n",
    "            timespan from the first date to the second one\n",
    "  \"\"\"\n",
    "  #build the url\n",
    "  keys_a = \"&apiKey=\" + api_key\n",
    "  date_a = '&to='+date2+'&from='+date1\n",
    "  if not query is None:\n",
    "    query = 'everything?q='+query + '&'\n",
    "  else:\n",
    "    query = 'everything?q='\n",
    "  url = \"https://newsapi.org/v2/\"+query\\\n",
    "        +'page='+str(page)+'&pageSize=' +str(N)+'&sortBy='+ sort +date_a+keys_a\n",
    "\n",
    "  agg_file = json.load(urllib.request.urlopen(url))\n",
    " \n",
    "  return agg_file\n",
    "\n",
    "\n",
    "def retrieve_news_article(N,key,date1,date2,order,query):\n",
    "  \"\"\"\n",
    "  retrieve N top results from the news API pool of news report\n",
    "\n",
    "  N: the total number of wanted news\n",
    "  key: the API key for access\n",
    "  query: the string query terms for the search, can be in the format\n",
    "   of  \"keyword\", \"keyword AND keyword\", \"keyword NOT keyword\", \n",
    "   \"keyword OR keyword\"\n",
    "   query (any operator) (query), \n",
    "   keyword (any operator) query\n",
    "   default is None\n",
    "  date11: the start date of the timespan from which we retrieve news\n",
    "    format: \"yyyy-mm-dd\"\n",
    "  date2: the end date of the time span from which we retrieve news\n",
    "  order: one of 'pubishedAt', 'relevancy',or 'popularity' \n",
    "  \"\"\"\n",
    "  results = []\n",
    "  date = date1+':'+date2\n",
    "  results_left = 1\n",
    "  page = 0\n",
    "  while results_left != 0:\n",
    "    instance = raw_news_retrieval(query,key,date1,date2,100,page,'publishedAt')\n",
    "    totalSize = instance['totalResults']\n",
    "    results.extend(instance['articles'])\n",
    "    results_left = totalSize-len(results)\n",
    "    if len(results) >= N:\n",
    "      return results[:N]\n",
    "    page = page + 1  \n",
    "  print(\"there are not enoguh results that can be retrieved, returning as many as we can\")\n",
    "  return (results)\n",
    "\n",
    "\n",
    "\n",
    "def news_Aggregated(N,date1,date2,order,query=None):\n",
    "  \"\"\"\n",
    "  retrieve N top results from the news API pool of news report\n",
    "  in the format specified in the degin doc (list of news, each represented by\n",
    "  a dicitonary)\n",
    "\n",
    "  N: the total number of wanted news\n",
    "  query: the string query terms for the search, can be in the format\n",
    "   of  \"keyword\", \"keyword AND keyword\", \"keyword NOT keyword\", \n",
    "   \"keyword OR keyword\"\n",
    "   query (any operator) (query), \n",
    "   keyword (any operator) query\n",
    "   default is None\n",
    "  date11: the start date of the timespan from which we retrieve news\n",
    "    format: \"yyyy-mm-dd\"\n",
    "  date2: the end date of the time span from which we retrieve news\n",
    "\n",
    "  (the time span can at most be one month)\n",
    "\n",
    "  order: one of 'pubishedAt', 'relevancy',or 'popularity' \n",
    "\n",
    "  libraries:\n",
    "  re\n",
    "  urllib\n",
    "  json\n",
    "  \"\"\"\n",
    "  instance = retrieve_news_article(N,'8ba8b6889b1343508e1ba0b55849ec31',date1,date2,order,query)\n",
    "  wanted = ['source','author','description','publi_time','url','content']\n",
    "  full1 = []\n",
    "  count = 0\n",
    "  for idx in instance:\n",
    "    data1 = {x:None for x in wanted}\n",
    "    data1['source'] = idx['source']['name']\n",
    "    data1['author'] = idx['author']\n",
    "    data1['description'] = idx['description']\n",
    "    data1['publi_time'] = idx['publishedAt']\n",
    "    data1['url'] = idx['url']\n",
    "    data1['content'] = idx['content']\n",
    "    full1.append(data1)\n",
    "    count += 1\n",
    "  return full1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZReypTXZfzEI"
   },
   "outputs": [],
   "source": [
    "def bing_retrieve_raw(N,query,key):\n",
    "  \"\"\"\n",
    "  retrieve API results from Bing News API specified under\n",
    "  https://docs.microsoft.com/en-us/rest/api/cognitiveservices-bingsearch/bing-news-api-v7-reference\n",
    "\n",
    "  N: the number of results wanted\n",
    "  query: the search keywords\n",
    "  \n",
    "  \"\"\"\n",
    "  #Bing API\n",
    "  search_url = \"https://api.cognitive.microsoft.com/bing/v7.0/news/search\"\n",
    "  headers = {\"Ocp-Apim-Subscription-Key\" : key}\n",
    "  q = ''\n",
    "  if not query is None:\n",
    "    q = query\n",
    "  params  = {\"q\": q, 'count':100,'offset':1,'mkt':'en-US'}\n",
    "  response = requests.get(search_url, headers=headers, params=params)\n",
    "  response.raise_for_status()\n",
    "  search_results = response.json()\n",
    "\n",
    "  while collected != N:\n",
    "  return search_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tiSnFW6mUhLv"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "wanted = ['id','is_video','num_comments','permalink','score','title','selftext','preview','url','domain']\n",
    "bing_key = '3903dc2afaba49208df3bcb91206fe22'\n",
    "exp = bing_retrieve_raw(1000,None,bing_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "cA4QmuN_pUd1",
    "outputId": "5ee9fac7-783b-41e5-a65c-5f2925fb5ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In his daily briefings on the coronavirus, President Donald Trump has brandished all the familiar tools in his rhetorical arsenal: belittling Democratic governors, demonizing the media, trading in innuendo and bulldozing over the guidance of experts. It’s the kind of performance the president relishes but one that has his advisers and ...\n",
      "AirPods are easy to misplace, we know. If you recently had to acquire a single replacement AirPod earbud, you might assume that all is now wellyour lonely AirPod now has a friend again. However, a number of Apple fans are reporting that their replacement AirP… [+1153 chars]\n"
     ]
    }
   ],
   "source": [
    "print(exp['value'][2]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XzBzznuDfkoV"
   },
   "source": [
    "Codes for Reddit API, now abandoned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "ZXB61SFEO8hl",
    "outputId": "bdc33874-2a18-4750-b140-4623ec111485"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aa2777504e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0magg_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit_sub_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2020-04-09-11-05'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2020-04-10-12-05'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-aa2777504e1d>\u001b[0m in \u001b[0;36mreddit_sub_retrieve\u001b[0;34m(N, query, date1, date2)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mquery_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'q='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'&'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdate1_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'after'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%Y-%m-%d-%H-%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mdate2_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'&before'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'%Y-%m-%d-%H-%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate1_e\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdate2_e\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'&subreddit=news'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def reddit_sub_retrieve(N,query,date1,date2):\n",
    "  \"\"\"\n",
    "  https://pushshift.io/api-parameters/\n",
    "  thanks pushshift\n",
    "  \"\"\"\n",
    "  url = \"https://api.pushshift.io/reddit/submission/search/?\"\n",
    "  query_t = ''\n",
    "  if query != None:\n",
    "    query_t = 'q=' + query + '&'\n",
    "  date1_e = 'after'+ str(datetime.strptime(date1,'%Y-%m-%d-%H-%S').timestamp())\n",
    "  date2_e = '&before'+ str(datetime.strptime(date2,'%Y-%m-%d-%H-%S').timestamp())\n",
    "  url = url + query_t + date1_e + date2_e + '&subreddit=news'\n",
    "  agg_file = json.load(urllib.request.urlopen(url))\n",
    "  return agg_file\n",
    "\n",
    "instance = reddit_sub_retrieve(0,None,'2020-04-09-11-05','2020-04-10-12-05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "oykdNFTPuLkx",
    "outputId": "0ab85794-e978-4c14-c8bc-37130835d9fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'Boingboing.net', 'author': \"Boing Boing's Shop\", 'description': \"If you've recently faced a major shift in where you work — as in, from an actual office to your home — you're probably in need of a little assistance to help you navigate that transition more smoothly. Or, maybe you’ve always worked from home, and now the res…\", 'publi_time': '2020-03-21T01:30:00Z', 'url': 'https://boingboing.net/2020/03/20/while-youre-stuck-at-home.html', 'content': \"If you've recently faced a major shift in where you work as in, from an actual office to your home you're probably in need of a little assistance to help you navigate that transition more smoothly. Or, maybe youve always worked from home, and now the rest of … [+6907 chars]\"}\n"
     ]
    }
   ],
   "source": [
    "print(full1[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kvGjls4Lw5Kx"
   },
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "5ooxc0ODB5TP",
    "outputId": "94ab0ee3-ed50-41dd-c2c2-822e84065180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.65\n",
      "264.306\n",
      "{'Lifehacker.com': (209.8181818181818, 22), 'Engadget': (260.0, 33), 'The Verge': (239.75, 8), 'TechCrunch': (250.0408163265306, 49), 'Theinventory.com': (173.66666666666666, 30), 'Gizmodo.com': (211.84615384615384, 39), 'Mashable': (260.0, 40), 'BBC News': (114.95833333333333, 24), 'CNN': (215.25, 8), 'Ars Technica': (75.5, 16), 'Blog.google': (260.0, 23), 'Reuters': (216.66666666666666, 3), 'Androidcentral.com': (259.9047619047619, 84), 'Cnet.com': (121.11504424778761, 113), 'Business Insider': (260.0, 240), 'Welt.de': (260.0, 9), 'Entrepreneur.com': (82.27272727272727, 55), 'Macrumors.com': (260.0, 13), 'Npr.org': (179.86666666666667, 15), 'Slashdot.org': (260.0, 9), 'Wired': (149.25, 8), 'Theconversation.com': (260.0, 3), 'Makezine.com': (238.0, 6), 'Worldpoliticsreview.com': (260.0, 1), 'Smashingmagazine.com': (260.0, 4), 'Canoe.com': (192.0, 2), 'Globalnews.ca': (260.0, 1), 'Mlive.com': (260.0, 1), 'Www.tsn.ca': (260.0, 1), 'Chessbase.com': (260.0, 2), 'Sudbury.com': (260.0, 1), 'Yahoo.com': (214.46153846153845, 13), 'Sportsnet.ca': (260.0, 6), 'Thescore.com': (260.0, 1), 'Readwrite.com': (250.4, 10), 'Kotaku.com': (177.875, 16), 'Hackaday.com': (260.0, 9), 'Boingboing.net': (260.0, 14), 'Venturebeat.com': (260.0, 2), 'The Next Web': (260.0, 8), 'Fastcompany.com': (260.0, 2), 'Hbr.org': (52.0, 1), 'Noozhawk.com': (158.0, 2), 'Design-milk.com': (148.0, 1), 'Time': (155.6, 5), 'Espn.com': (137.33333333333334, 3), 'Huffpost.com': (105.0, 7), 'Newswire.ca': (260.0, 1), 'Toofab.com': (260.0, 1), 'Hipertextual.com': (260.0, 1), 'Polygon': (260.0, 2), 'Xataka.com': (260.0, 4), 'Hubspot.com': (239.6, 5), 'Sciencemag.org': (260.0, 8), 'ABC News': (124.2, 5), 'Artofmanliness.com': (260.0, 1), 'USA Today': (104.0, 7), 'Military.com': (260.0, 1), 'Airforcetimes.com': (260.0, 1)}\n",
      "{'Lifehacker.com': (274.0, 22), 'Engadget': (274.09090909090907, 33), 'The Verge': (274.125, 8), 'TechCrunch': (274.16326530612247, 49), 'Theinventory.com': (275.0, 30), 'Gizmodo.com': (274.1794871794872, 39), 'Mashable': (274.025, 40), 'BBC News': (274.2083333333333, 24), 'CNN': (274.375, 8), 'Ars Technica': (274.1875, 16), 'Blog.google': (273.9130434782609, 23), 'Reuters': (273.6666666666667, 3), 'Androidcentral.com': (274.14285714285717, 84), 'Cnet.com': (274.46902654867256, 113), 'Business Insider': (245.45416666666668, 240), 'Welt.de': (275.0, 9), 'Entrepreneur.com': (274.0, 55), 'Macrumors.com': (273.84615384615387, 13), 'Npr.org': (274.0, 15), 'Slashdot.org': (273.77777777777777, 9), 'Wired': (274.0, 8), 'Theconversation.com': (0.0, 3), 'Makezine.com': (274.6666666666667, 6), 'Worldpoliticsreview.com': (0.0, 1), 'Smashingmagazine.com': (275.0, 4), 'Canoe.com': (274.0, 2), 'Globalnews.ca': (274.0, 1), 'Mlive.com': (274.0, 1), 'Www.tsn.ca': (274.0, 1), 'Chessbase.com': (274.0, 2), 'Sudbury.com': (274.0, 1), 'Yahoo.com': (253.15384615384616, 13), 'Sportsnet.ca': (274.0, 6), 'Thescore.com': (274.0, 1), 'Readwrite.com': (274.3, 10), 'Kotaku.com': (274.5, 16), 'Hackaday.com': (274.1111111111111, 9), 'Boingboing.net': (274.0, 14), 'Venturebeat.com': (275.0, 2), 'The Next Web': (273.875, 8), 'Fastcompany.com': (273.5, 2), 'Hbr.org': (274.0, 1), 'Noozhawk.com': (274.0, 2), 'Design-milk.com': (274.0, 1), 'Time': (274.2, 5), 'Espn.com': (275.0, 3), 'Huffpost.com': (274.0, 7), 'Newswire.ca': (274.0, 1), 'Toofab.com': (274.0, 1), 'Hipertextual.com': (274.0, 1), 'Polygon': (274.5, 2), 'Xataka.com': (275.0, 4), 'Hubspot.com': (275.0, 5), 'Sciencemag.org': (68.375, 8), 'ABC News': (274.2, 5), 'Artofmanliness.com': (274.0, 1), 'USA Today': (274.85714285714283, 7), 'Military.com': (274.0, 1), 'Airforcetimes.com': (274.0, 1)}\n"
     ]
    }
   ],
   "source": [
    "average_length1 = {}\n",
    "average_length2 = {}\n",
    "length1 = 0\n",
    "length2 = 0\n",
    "for ins in full1:\n",
    "  old1 = average_length1.get(ins['source'],(0,0))\n",
    "  old2 = average_length2.get(ins['source'],(0,0))\n",
    "  average_length1[ins['source']] = (old1[0]+len(ins['description']),old1[1]+1)\n",
    "  if ins['content'] is not None:\n",
    "    average_length2[ins['source']] = (old2[0]+len(ins['content']),old2[1]+1)\n",
    "    length2 += len(ins['content'])\n",
    "  else:\n",
    "    average_length2[ins['source']] = (old2[0]+0,old2[1]+1)\n",
    "    length2 += 0\n",
    "  length1 += len(ins['description'])\n",
    "\n",
    "for keys in average_length1.keys():\n",
    "  average_length1[keys] = (average_length1[keys][0]/average_length1[keys][1],average_length1[keys][1])\n",
    "  average_length2[keys] = (average_length2[keys][0]/average_length2[keys][1],average_length1[keys][1])\n",
    "length1 = length1/len(full1)\n",
    "length2 = length2/len(full1)\n",
    "\n",
    "print(length1)\n",
    "print(length2)\n",
    "print(average_length1)\n",
    "print(average_length2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "XGNiMCQOF12h",
    "outputId": "586226f9-eb1f-486a-8689-df95e720526d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 33, 8, 49, 30, 39, 40, 24, 8, 16, 23, 3, 84, 113, 240, 9, 55, 13, 15, 9, 8, 3, 6, 1, 4, 2, 1, 1, 1, 2, 1, 13, 6, 1, 10, 16, 9, 14, 2, 8, 2, 1, 2, 1, 5, 3, 7, 1, 1, 1, 2, 4, 5, 8, 5, 1, 7, 1, 1]\n",
      "[274.0, 274.09090909090907, 274.125, 274.16326530612247, 275.0, 274.1794871794872, 274.025, 274.2083333333333, 274.375, 274.1875, 273.9130434782609, 273.6666666666667, 274.14285714285717, 274.46902654867256, 245.45416666666668, 275.0, 274.0, 273.84615384615387, 274.0, 273.77777777777777, 274.0, 0.0, 274.6666666666667, 0.0, 275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 253.15384615384616, 274.0, 274.0, 274.3, 274.5, 274.1111111111111, 274.0, 275.0, 273.875, 273.5, 274.0, 274.0, 274.0, 274.2, 275.0, 274.0, 274.0, 274.0, 274.0, 274.5, 275.0, 275.0, 68.375, 274.2, 274.0, 274.85714285714283, 274.0, 274.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "des = []\n",
    "content = []\n",
    "x_label = []\n",
    "for keys in average_length1.keys():\n",
    "  des.append(average_length1[keys][0])\n",
    "  content.append(average_length2[keys][0])\n",
    "  x_label.append(average_length1[keys][1])\n",
    "\n",
    "\n",
    "print(x_label)\n",
    "print(content)\n",
    "\n",
    "plt.plot(x_label,des, '.k')\n",
    "plt.plot(x_label,content, '.r')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yxj7vIFew_7Z"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Guardian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhtFK-SczSY2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_q(query):\n",
    "  result = ''\n",
    "  if type(query) == str:\n",
    "    #the base case\n",
    "    return query\n",
    "  else:\n",
    "    if query[1] == 0:\n",
    "      op = '%20NOT%20'\n",
    "      return '('+op + generate_q(query[0])+')'\n",
    "    else:\n",
    "      if query[1] == 1:\n",
    "        op =  '%20AND%20'\n",
    "      else:\n",
    "        op =  '%20OR%20'\n",
    "      return '('+generate_q(query[0][0]) + op + generate_q(query[0][1])+')'\n",
    "\n",
    "def raw_g_retrieval(query,api_key,time_span,N,page):\n",
    "  \"\"\"\n",
    "  return a json file specified in https://open-platform.theguardian.com/documentation/search\n",
    "  query: a tuple or a keyword, the tuple should represent\n",
    "        a relation\n",
    "        ((a,b),1) -> a and b\n",
    "        ((a,b),2) -> a or b\n",
    "        ((a,(b,0)),1) -> a and NOT b\n",
    "        (((a,b),1),(((c,d),2),0),1) = (a AND B) AND NOT (c OR d)\n",
    "        means reddit AND NOT news AND (random or guardian)\n",
    "  api_key: the auth key to retrieve the news\n",
    "  time_span: a string in the format of 'yyyy-mm-dd:yyyy-mm-dd' indicating the\n",
    "            timespan from the first date to the second one\n",
    "  \"\"\"\n",
    "  #build the url\n",
    "  date = re.split(':',time_span)\n",
    "  keys_a = \"&api-key=\" + api_key\n",
    "  date_a = '&to-date='+date[1]+'&from-date='+date[0]\n",
    "  if not query is None:\n",
    "    query = 'search?q='+generate_q(query) + '&'\n",
    "  else:\n",
    "    query = 'search?'\n",
    "  url = \"https://content.guardianapis.com/\"+query+'show-blocks=all'+'&format=json'\\\n",
    "        +'&page='+str(page)+'&page-size=' +str(N)+date_a+keys_a\n",
    "\n",
    "  agg_file = json.load(urllib.request.urlopen(url))\n",
    "  return agg_file\n",
    "\n",
    "\n",
    "def retrieve_g_article(N,key,query,date1,date2):\n",
    "  results = []\n",
    "  date_counter = date2+':'+date2\n",
    "  start_date = datetime.strptime(date2,'%Y-%m-%d')\n",
    "  end_date = datetime.strptime(date1,'%Y-%m-%d')\n",
    "  while len(results)<N and start_date>=end_date:\n",
    "    instance = raw_g_retrieval(query,key,date_counter,200)\n",
    "    for idx in instance['response']['results']:\n",
    "      if idx['type'] == 'article':\n",
    "        results.append(idx)\n",
    "        if len(results) == N:\n",
    "          break\n",
    "    start_date = start_date - timedelta(days=1)\n",
    "    new_date = start_date.strftime(\"%Y-%m-%d\")\n",
    "    date_counter =  new_date+':'+new_date\n",
    "  return results\n",
    "\n",
    "def retrieve_g_article1(N,key,query,date1,date2):\n",
    "  results = []\n",
    "  date = date1+':'+date2\n",
    "  page_left = 1\n",
    "  page = 1\n",
    "  while page_left != 0:\n",
    "    instance = raw_g_retrieval(query,key,date,200,page)\n",
    "    \n",
    "    pageSize = instance['response']['pageSize']\n",
    "    currentPage = instance['response']['currentPage']\n",
    "    for idx in instance['response']['results']:\n",
    "      if idx['type'] == 'article':\n",
    "        results.append(idx)\n",
    "        if len(results) == N:\n",
    "          return results \n",
    "    \n",
    "    page_left = pageSize-currentPage\n",
    "    page = page + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "qVHPa543CgfM",
    "outputId": "68bd004a-2ab5-4669-dd88-3c8d5bc2ed68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'crosswords/2020/apr/06/annotated-solutions-for-genius-201', 'type': 'article', 'sectionId': 'crosswords', 'sectionName': 'Crosswords', 'webPublicationDate': '2020-04-05T23:01:41Z', 'webTitle': 'Annotated solutions for Genius 201', 'webUrl': 'https://www.theguardian.com/crosswords/2020/apr/06/annotated-solutions-for-genius-201', 'apiUrl': 'https://content.guardianapis.com/crosswords/2020/apr/06/annotated-solutions-for-genius-201', 'blocks': {'body': [{'id': '5e887b618f08c35a1d119ee4', 'bodyHtml': '<p>* In Victor Borge’s ‘Inflationary Language’ ‘four’ and ‘for’, for example, became ‘five’. Here, when the solutions defined in the clues that contain numbers (or homophones of numbers), these must be treated in the same way before entry in the grid.</p> <h2>Across</h2> <p><strong>5</strong> phtwo-in/phone-in P(ublic)H(ouse) + TW&lt;O(rdered)&gt;IN </p> <p><strong>7</strong> captwo/Capone COWPAT (anag)</p> <p><strong>9</strong> throatee/boat race THR&lt;OAT&gt;EE [brace/three] </p> <p><strong>10</strong> Beirut B&lt;(p)E{1}R(u)&gt;UT</p> <p><strong>12</strong> Eden draiNED Economy (hidden rev) </p> <p><strong>13</strong> give rise to cryptic def</p> <p><strong>15</strong> Incas IN CAS(e)</p> <p><strong>16</strong> ale teA LEaves (hidden)</p> <p><strong>18</strong> raccoon dog RA&lt;C(old)/CO{0}ONDO&gt;G</p> <p><strong>19</strong> Hutu (s)HUT/U(p)</p> <p><strong>21</strong> myelin MY + NILE (rev)</p> <p><strong>22</strong> go and see GOAN/D&lt;(gange)S&gt;EE</p> <p><strong>23</strong> Nasdaq (liquidatio)N&lt;ASDA&gt;Q(ueen)</p> <p><strong>24</strong> mistime M&lt;I{(flea)S}T&gt;IME</p> <h2>Down</h2> <p><strong>1</strong> Charles Dickens CH&lt;ARLES/D(ied)&gt;ICKENS</p> <p><strong>2</strong> fivenicnine/fornicate IF(rev)/VENIC&lt;(desperation)N/IN&gt;E</p> <p><strong>3</strong> take six/take five cryptic def</p> <p><strong>4</strong> fortyonetude/fortitude F&lt;OR&gt;T YON ETUDE [40/41]</p> <p><strong>6</strong> wham H(ard) in MAW (rev)</p> <p><strong>9</strong> the sacrament THE&lt;SACRA&gt;ME/N(ew)T(estament)</p> <p><strong>11</strong> megalopolis GALOP/(tang)O in SMILE (anag)</p> <p><strong>17,14,8</strong> fonidad and threebagursome/Trinidad and Tobago</p> <p>FO&lt;NIDADANDTHREEBAG&gt;URSOME [trio/foursome; to/three]</p> <p><strong>20</strong> lnet/Lenin L + TEN (rev) [9/10]</p>', 'bodyTextSummary': '* In Victor Borge’s ‘Inflationary Language’ ‘four’ and ‘for’, for example, became ‘five’. Here, when the solutions defined in the clues that contain numbers (or homophones of numbers), these must be treated in the same way before entry in the grid. Across 5 phtwo-in/phone-in P(ublic)H(ouse) + TW<O(rdered)>IN 7 captwo/Capone COWPAT (anag) 9 throatee/boat race THR<OAT>EE [brace/three] 10 Beirut B<(p)E{1}R(u)>UT 12 Eden draiNED Economy (hidden rev) 13 give rise to cryptic def 15 Incas IN CAS(e) 16 ale teA LEaves (hidden) 18 raccoon dog RA<C(old)/CO{0}ONDO>G 19 Hutu (s)HUT/U(p) 21 myelin MY + NILE (rev) 22 go and see GOAN/D<(gange)S>EE 23 Nasdaq (liquidatio)N<ASDA>Q(ueen) 24 mistime M<I{(flea)S}T>IME Down 1 Charles Dickens CH<ARLES/D(ied)>ICKENS 2 fivenicnine/fornicate IF(rev)/VENIC<(desperation)N/IN>E 3 take six/take five cryptic def 4 fortyonetude/fortitude F<OR>T YON ETUDE [40/41] 6 wham H(ard) in MAW (rev) 9 the sacrament THE<SACRA>ME/N(ew)T(estament) 11 megalopolis GALOP/(tang)O in SMILE (anag) 17,14,8 fonidad and threebagursome/Trinidad and Tobago FO<NIDADANDTHREEBAG>URSOME [trio/foursome; to/three] 20 lnet/Lenin L + TEN (rev) [9/10]', 'attributes': {}, 'published': True, 'createdDate': '2020-04-04T12:19:45Z', 'firstPublishedDate': '2020-04-04T12:19:45Z', 'publishedDate': '2020-04-04T12:22:23Z', 'lastModifiedDate': '2020-04-04T12:22:23Z', 'contributors': [], 'elements': [{'type': 'text', 'assets': [], 'textTypeData': {'html': '<p>* In Victor Borge’s ‘Inflationary Language’ ‘four’ and ‘for’, for example, became ‘five’. Here, when the solutions defined in the clues that contain numbers (or homophones of numbers), these must be treated in the same way before entry in the grid.</p> \\n<h2>Across</h2> \\n<p><strong>5</strong> phtwo-in/phone-in P(ublic)H(ouse) + TW&lt;O(rdered)&gt;IN </p> \\n<p><strong>7</strong> captwo/Capone COWPAT (anag)</p> \\n<p><strong>9</strong> throatee/boat race THR&lt;OAT&gt;EE [brace/three] </p> \\n<p><strong>10</strong> Beirut B&lt;(p)E{1}R(u)&gt;UT</p> \\n<p><strong>12</strong> Eden draiNED Economy (hidden rev) </p> \\n<p><strong>13</strong> give rise to cryptic def</p> \\n<p><strong>15</strong> Incas IN CAS(e)</p> \\n<p><strong>16</strong> ale teA LEaves (hidden)</p> \\n<p><strong>18</strong> raccoon dog RA&lt;C(old)/CO{0}ONDO&gt;G</p> \\n<p><strong>19</strong> Hutu (s)HUT/U(p)</p> \\n<p><strong>21</strong> myelin MY + NILE (rev)</p> \\n<p><strong>22</strong> go and see GOAN/D&lt;(gange)S&gt;EE</p> \\n<p><strong>23</strong> Nasdaq (liquidatio)N&lt;ASDA&gt;Q(ueen)</p> \\n<p><strong>24</strong> mistime M&lt;I{(flea)S}T&gt;IME</p> \\n<h2>Down</h2> \\n<p><strong>1</strong> Charles Dickens CH&lt;ARLES/D(ied)&gt;ICKENS</p> \\n<p><strong>2</strong> fivenicnine/fornicate IF(rev)/VENIC&lt;(desperation)N/IN&gt;E</p> \\n<p><strong>3</strong> take six/take five cryptic def</p> \\n<p><strong>4</strong> fortyonetude/fortitude F&lt;OR&gt;T YON ETUDE [40/41]</p> \\n<p><strong>6</strong> wham H(ard) in MAW (rev)</p> \\n<p><strong>9</strong> the sacrament THE&lt;SACRA&gt;ME/N(ew)T(estament)</p> \\n<p><strong>11</strong> megalopolis GALOP/(tang)O in SMILE (anag)</p> \\n<p><strong>17,14,8</strong> fonidad and threebagursome/Trinidad and Tobago</p> \\n<p>FO&lt;NIDADANDTHREEBAG&gt;URSOME [trio/foursome; to/three]</p> \\n<p><strong>20</strong> lnet/Lenin L + TEN (rev) [9/10]</p>'}}]}], 'totalBodyBlocks': 1}, 'isHosted': False, 'pillarId': 'pillar/lifestyle', 'pillarName': 'Lifestyle'}\n",
      "0:00:30.611427\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import re\n",
    "import urllib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "\n",
    "start = datetime.now()\n",
    "instance = retrieve_g_article1(2000,'7dd62f93-de59-4cb6-a166-e7c44543477d',None,'2020-01-01','2020-04-05')\n",
    "print(instance[0])\n",
    "wanted = ['sectionName','webTitle','content','publi_time','url']\n",
    "full = []\n",
    "count = 0\n",
    "for idx in instance:\n",
    "  data = {x:None for x in wanted}\n",
    "  data['sectionName'] = idx['sectionName']\n",
    "  data['webTitle'] = idx['webTitle']\n",
    "  data['publi_time'] = idx['webPublicationDate']\n",
    "  data['content'] = idx['blocks']['body'][0]['bodyTextSummary']\n",
    "  data['url'] = idx['webUrl']\n",
    "  full.append(data)\n",
    "  count += 1\n",
    "\n",
    "print(datetime.now()-start)\n",
    "with open('/content/drive/My Drive/Guardian_News.txt',\"w\") as outfile:\n",
    "  json.dump(full,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbDPytQBSMfE"
   },
   "outputs": [],
   "source": [
    "list0 = []\n",
    "for ins in full:\n",
    "  list0.append(len(ins['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "Edd42ZziSEbl",
    "outputId": "d6dec4c8-e471-49d2-db2c-a35a02edc9a3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-df309e45b1d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list0' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(max(list0))\n",
    "\n",
    "\n",
    "plt.hist(list0)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "913bZB9VDBw0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "AdHoc_Data_Crawl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
